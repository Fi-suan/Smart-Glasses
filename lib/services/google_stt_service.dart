import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:permission_handler/permission_handler.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';

/// –°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Google Cloud Speech-to-Text API
class GoogleSttService {
  static final GoogleSttService _instance = GoogleSttService._internal();
  factory GoogleSttService() => _instance;

  GoogleSttService._internal();

  // API –∫–ª—é—á —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º Speech-to-Text
  static const String _apiKey = 'AIzaSyDHLPatV3_3xG1cdx0nvEhxCdn2XEgnzac';
  static const String _apiUrl =
      'https://speech.googleapis.com/v1/speech:recognize?key=$_apiKey';

  final AudioRecorder _audioRecorder = AudioRecorder();
  bool _isListening = false;
  String? _recordingPath;

  bool get isListening => _isListening;

  /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ (–∑–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π)
  Future<bool> initialize() async {
    try {
      final micPermission = await Permission.microphone.request();
      if (micPermission.isGranted) {
        debugPrint('‚úÖ Google STT initialized');
        return true;
      } else {
        debugPrint('‚ö†Ô∏è Microphone permission denied');
        return false;
      }
    } catch (e) {
      debugPrint('‚ùå Google STT initialization error: $e');
      return false;
    }
  }

  /// –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞
  Future<bool> startListening() async {
    if (_isListening) {
      debugPrint('‚ö†Ô∏è Already listening');
      return false;
    }

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
      if (!await Permission.microphone.isGranted) {
        final status = await Permission.microphone.request();
        if (!status.isGranted) {
          debugPrint('‚ö†Ô∏è Microphone permission denied');
          return false;
        }
      }

      // –ü–æ–ª—É—á–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
      final tempDir = await getTemporaryDirectory();
      _recordingPath = '${tempDir.path}/${DateTime.now().millisecondsSinceEpoch}.wav';

      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å –≤ WAV —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Google STT
      await _audioRecorder.start(
        const RecordConfig(
          encoder: AudioEncoder.wav,
          sampleRate: 16000,
          numChannels: 1,
          bitRate: 128000,
        ),
        path: _recordingPath!,
      );

      _isListening = true;
      debugPrint('üé§ Recording started: $_recordingPath');
      return true;
    } catch (e) {
      debugPrint('‚ùå Error starting recording: $e');
      _isListening = false;
      return false;
    }
  }

  /// –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å
  Future<String?> stopListening() async {
    if (!_isListening) {
      debugPrint('‚ö†Ô∏è Not listening');
      return null;
    }

    try {
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å
      final path = await _audioRecorder.stop();
      _isListening = false;

      if (path == null) {
        debugPrint('‚ö†Ô∏è No recording path');
        return null;
      }

      debugPrint('üé§ Recording stopped: $path');

      // –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
      final audioBytes = await _readAudioFile(path);
      if (audioBytes == null) {
        debugPrint('‚ö†Ô∏è Failed to read audio file');
        return null;
      }

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
      final text = await _recognizeSpeech(audioBytes);
      return text;
    } catch (e) {
      debugPrint('‚ùå Error stopping recording: $e');
      _isListening = false;
      return null;
    }
  }

  /// –ü—Ä–æ—á–∏—Ç–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª
  Future<Uint8List?> _readAudioFile(String path) async {
    try {
      final file = File(path);
      if (!await file.exists()) {
        debugPrint('‚ö†Ô∏è Audio file not found: $path');
        return null;
      }

      final bytes = await file.readAsBytes();
      debugPrint('‚úÖ Read ${bytes.length} bytes from audio file');
      return bytes;
    } catch (e) {
      debugPrint('‚ùå Error reading audio file: $e');
      return null;
    }
  }

  /// –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∞—É–¥–∏–æ –Ω–∞ Google Cloud STT
  Future<String?> _recognizeSpeech(Uint8List audioBytes) async {
    try {
      // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫ (44 –±–∞–π—Ç–∞) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —á–∏—Å—Ç–æ–≥–æ PCM
      final pcmData = audioBytes.sublist(44);

      // –ö–æ–¥–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ base64
      final base64Audio = base64Encode(pcmData);

      debugPrint('üåê Sending ${pcmData.length} bytes to Google STT...');

      // –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
      final requestBody = {
        'config': {
          'encoding': 'LINEAR16',
          'sampleRateHertz': 16000,
          'languageCode': 'ru-RU',
          'model': 'default',
          'enableAutomaticPunctuation': true,
        },
        'audio': {
          'content': base64Audio,
        },
      };

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
      final response = await http.post(
        Uri.parse(_apiUrl),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode(requestBody),
      ).timeout(const Duration(seconds: 30));

      debugPrint('üì° Google STT response: ${response.statusCode}');

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        debugPrint('Response data: $data');

        if (data['results'] != null && data['results'].isNotEmpty) {
          final transcript =
              data['results'][0]['alternatives'][0]['transcript'] as String;
          debugPrint('‚úÖ Google STT result: $transcript');
          return transcript;
        } else {
          debugPrint('‚ö†Ô∏è No transcription results - speech may be too quiet or unclear');
          return null;
        }
      } else {
        debugPrint('‚ùå Google STT error: ${response.statusCode}');
        debugPrint('Response: ${response.body}');
        return null;
      }
    } catch (e) {
      debugPrint('‚ùå Error recognizing speech: $e');
      return null;
    }
  }

  /// –û—Ç–º–µ–Ω–∏—Ç—å –∑–∞–ø–∏—Å—å
  Future<void> cancel() async {
    if (_isListening) {
      await _audioRecorder.stop();
      _isListening = false;
      debugPrint('üé§ Recording cancelled');
    }
  }

  /// –û—Å–≤–æ–±–æ–¥–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã
  Future<void> dispose() async {
    await _audioRecorder.dispose();
  }
}
